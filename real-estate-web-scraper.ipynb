{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c088b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d9e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrapper...\n",
      "Scraping rental properties...\n",
      "✗ Rent page 24 connection error, skipping...\n",
      "✗ Rent page 41 connection error, skipping...\n",
      "✗ Rent page 48 connection error, skipping...\n",
      "✗ Rent page 50 connection error, skipping...\n",
      "✗ Rent page 57 connection error, skipping...\n",
      "✗ Rent page 61 connection error, skipping...\n",
      "✗ Sale page 7 connection error, skipping...\n",
      "✗ Sale page 19 timed out, skipping...\n",
      "✗ Sale page 28 connection error, skipping...\n",
      "✗ Sale page 74 connection error, skipping...\n",
      "✗ Sale page 86 connection error, skipping...\n",
      "✗ Sale page 87 connection error, skipping...\n",
      "✗ Sale page 88 connection error, skipping...\n",
      "✗ Sale page 96 connection error, skipping...\n",
      "✗ Sale page 110 timed out, skipping...\n",
      "✗ Sale page 173 connection error, skipping...\n",
      "✗ Sale page 175 connection error, skipping...\n",
      "✗ Sale page 183 connection error, skipping...\n",
      "✗ Sale page 189 connection error, skipping...\n",
      "Scraping completed in 1598.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Column Lists\n",
    "\n",
    "title_col = []\n",
    "location_col = []\n",
    "price_col = []\n",
    "bedroom_col = []\n",
    "bathroom_col = []\n",
    "toilet_col = []\n",
    "property_type_col = []\n",
    "link_col = []\n",
    "\n",
    "print(\"Starting scrapper...\")\n",
    "\n",
    "#RENT PROPERTIES IN AJAH - Pages 1 t 64\n",
    "\n",
    "print(\"Scraping rental properties...\")\n",
    "for page in range(1,65):\n",
    "  url = f\"https://nigeriapropertycentre.com/for-rent?keywords=ajah&page={page}\"\n",
    "\n",
    "  try:\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "    response = requests.get(url, timeout=15, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    property_listing = soup.find(\"div\", {\"itemtype\": \"https://schema.org/ItemList\"})\n",
    "\n",
    "    #TITLES\n",
    "    titles = property_listing.find_all(\"h3\", {\"itemprop\": \"name\"})\n",
    "    for title in titles:\n",
    "      title_col.append(title.text.strip())\n",
    "\n",
    "    #LOCATIONS\n",
    "    addresses = property_listing.find_all(\"address\", class_ = \"voffset-bottom-10\")\n",
    "    for address in addresses:\n",
    "      location_col.append(address.strong.text.strip())\n",
    "\n",
    "    #PRICES\n",
    "    prices = property_listing.find_all(\"span\", class_=\"price\")\n",
    "    for i in range(1, len(prices), 2):\n",
    "      price_col.append(f\"₦ {prices[i].text} per annum\")\n",
    "\n",
    "    #ROOMS (bedroom, bathroom, toilet)\n",
    "    rooms_container = property_listing.find_all(\"ul\", class_=\"aux-info\")\n",
    "    for container in rooms_container:\n",
    "      room_items = container.find_all(\"li\")\n",
    "\n",
    "      #Bedroom\n",
    "      bedroom = room_items[0].text.strip()\n",
    "      bedroom_col.append(bedroom)\n",
    "\n",
    "      #Bathroom and Toilet\n",
    "      if \"Bathroom\" in container.text or \"Bathrooms\" in container.text:\n",
    "        bathroom = room_items[1].text.strip()\n",
    "        bathroom_col.append(bathroom)\n",
    "        if \"Toilet\" in container.text or \"Toilets\" in container.text:\n",
    "          toilet = room_items[2].text.strip()\n",
    "          toilet_col.append(toilet)\n",
    "        else:\n",
    "          toilet_col.append(\"N/A\")\n",
    "      else:\n",
    "        bathroom_col.append(\"N/A\")\n",
    "        if \"Toilet\" in container.text or \"Toilets\" in container.text:\n",
    "          toilet = room_items[1].text\n",
    "          toilet_col.append(toilet)\n",
    "        else:\n",
    "          toilet_col.append(\"N/A\")\n",
    "\n",
    "    #PROPERTY TYPE\n",
    "    property_type_container = property_listing.find_all(\"h4\", class_=\"content-title\")\n",
    "    for property_type in property_type_container:\n",
    "      property_type_col.append(property_type.text.strip())\n",
    "\n",
    "    #LINKS\n",
    "    links_container = property_listing.find_all(\"div\", class_=\"description\")\n",
    "    for links in links_container:\n",
    "      link = links.a[\"href\"]\n",
    "      link_col.append(f\"https://nigeriapropertycentre.com{link}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "  except requests.Timeout:\n",
    "        print(f\"✗ Rent page {page} timed out, skipping...\")\n",
    "        continue\n",
    "  except requests.ConnectionError:\n",
    "        print(f\"✗ Rent page {page} connection error, skipping...\")\n",
    "        continue\n",
    "  except Exception as e:\n",
    "        print(f\"✗ Rent page {page} error: {e}, skipping...\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# SALE PROPERTIES IN AJAH - Pages 1 to 200\n",
    "\n",
    "for page in range(1,201):\n",
    "  url = f\"https://nigeriapropertycentre.com/for-sale?keywords=ajah&page={page}\"\n",
    "\n",
    "  try:\n",
    "    response = requests.get(url, timeout=15, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    \n",
    "    property_listing = soup.find(\"div\", {\"itemtype\": \"https://schema.org/ItemList\"})\n",
    "\n",
    "    #TITLES\n",
    "    titles = property_listing.find_all(\"h3\", {\"itemprop\": \"name\"})\n",
    "    for title in titles:\n",
    "      title_col.append(title.text.strip())\n",
    "\n",
    "    #LOCATIONS\n",
    "    addresses = property_listing.find_all(\"address\", class_ = \"voffset-bottom-10\")\n",
    "    for address in addresses:\n",
    "      location_col.append(address.strong.text.strip())\n",
    "\n",
    "    #PRICES\n",
    "    prices = property_listing.find_all(\"span\", class_=\"price\")\n",
    "    for i in range(1, len(prices), 2):\n",
    "      price_col.append(f\"₦ {prices[i].text.strip()}\")\n",
    "\n",
    "    #ROOMS\n",
    "    rooms_container = property_listing.find_all(\"ul\", class_=\"aux-info\")\n",
    "    for container in rooms_container:\n",
    "      room_items = container.find_all(\"li\")\n",
    "      bedroom = room_items[0].text.strip()\n",
    "      bedroom_col.append(bedroom)\n",
    "\n",
    "      if \"Bathroom\" in container.text or \"Bathrooms\" in container.text:\n",
    "        bathroom = room_items[1].text.strip()\n",
    "        bathroom_col.append(bathroom)\n",
    "        if \"Toilet\" in container.text or \"Toilets\" in container.text:\n",
    "          toilet = room_items[2].text.strip()\n",
    "          toilet_col.append(toilet)\n",
    "        else:\n",
    "          toilet_col.append(\"N/A\")\n",
    "      else:\n",
    "        bathroom_col.append(\"N/A\")\n",
    "        if \"Toilet\" in container.text or \"Toilets\" in container.text:\n",
    "          toilet = room_items[1].text.strip()\n",
    "          toilet_col.append(toilet)\n",
    "        else:\n",
    "          toilet_col.append(\"N/A\")\n",
    "\n",
    "    #PROPERTY TYPE\n",
    "    property_type_container = property_listing.find_all(\"h4\", class_=\"content-title\")\n",
    "    for property_type in property_type_container:\n",
    "      property_type_col.append(property_type.text.strip())\n",
    "\n",
    "    #LINKS\n",
    "    links_container = property_listing.find_all(\"div\", class_=\"description\")\n",
    "    for links in links_container:\n",
    "      link = links.a[\"href\"]\n",
    "      link_col.append(f\"https://nigeriapropertycentre.com{link}\")\n",
    "    time.sleep(1)\n",
    "  except requests.Timeout:\n",
    "      print(f\"✗ Sale page {page} timed out, skipping...\")\n",
    "      continue\n",
    "  except requests.ConnectionError:\n",
    "      print(f\"✗ Sale page {page} connection error, skipping...\")\n",
    "      continue\n",
    "  except Exception as e:\n",
    "      print(f\"✗ Sale page {page} error: {e}, skipping...\")\n",
    "      continue\n",
    "\n",
    "print(f\"Scraping completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "#Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "   \"Title\": title_col,\n",
    "   \"Location\": location_col,\n",
    "   \"Price\": price_col,\n",
    "   \"Bedrooms\": bedroom_col,\n",
    "   \"Bathrooms\": bathroom_col,\n",
    "   \"Toilets\": toilet_col,\n",
    "   \"Property Type\": property_type_col,\n",
    "   \"URL\": link_col\n",
    " }, index=range(1, len(title_col)+1))\n",
    "\n",
    "df.to_csv(\"ajah_properties.csv\", index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def scrape_all_pages_parallel(start_page: int = 1, end_page: int = 300, max_worker: int = 5):\n",
    "#   \"\"\"\n",
    "#   Scrape multiple pages at the same time using threading.\n",
    "\n",
    "#   Parameters:\n",
    "#   - start_page: Firstpage to scrape\n",
    "#   - end_page: Last page to scrape\n",
    "#   - max_worker:How many pages to scrape simultaneously  \n",
    "  \n",
    "#   \"\"\"\n",
    "\n",
    "#   all_data ={\n",
    "#     \"Titles\": [],\n",
    "#     \"Locations\": [],\n",
    "#     \"Prices\": [],\n",
    "#     \"Bedrooms\": [],\n",
    "#     \"Bathrooms\": [],\n",
    "#     \"Toilets\": [],\n",
    "#     \"Property_Type\": [],\n",
    "#     \"URLs\": []\n",
    "#   }\n",
    "\n",
    "#   print(f\"Starting scrapes of pages {start_page} to {end_page}...\")\n",
    "#   start_time = time.time()\n",
    "\n",
    "#   with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
